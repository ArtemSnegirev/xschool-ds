{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "rs = 100\n",
    "\n",
    "nltk_sw = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "manual_sw = set([\n",
    "    'chat',\n",
    "    'transcript',\n",
    "    'alexandra',\n",
    "    'visitor',\n",
    "    'xsolla',\n",
    "    'please',\n",
    "    'thank',\n",
    "    'hello',\n",
    "    'ok',\n",
    "    'hi'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_word_with_digits = re.compile('([A-Za-z]*[\\d]+[\\w]*|[\\d]+[A-Za-z]+[\\w]*)')\n",
    "\n",
    "\n",
    "def preprocess(text, options=()):\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove chars has not 31-128 index in ascii table\n",
    "    text = ''.join([i if 31 < ord(i) < 128 else ' ' for i in text])\n",
    "\n",
    "    if 'word_with_digits' in options:\n",
    "        text = match_word_with_digits.sub(r' ', text)\n",
    "\n",
    "    # remove double spaces and apply lower transformation\n",
    "    tokens = word_tokenize(text.strip())\n",
    "\n",
    "    sw = set()\n",
    "\n",
    "    if 'nltk_stopwords' in options:\n",
    "        sw = sw.union(nltk_sw)\n",
    "\n",
    "    if 'manual_stopwords' in options:\n",
    "        sw = sw.union(manual_sw)\n",
    "\n",
    "    if len(sw) > 0:\n",
    "        tokens = [t for t in tokens if not t in sw]\n",
    "\n",
    "    if 'lemmatization' in options:\n",
    "        # apply lemmatizer\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    if 'punctuation' in options:\n",
    "        # remove punctuation\n",
    "        tokens = [t for t in tokens if t not in string.punctuation]\n",
    "\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/3categories_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "afs      35172\n",
       "other     8443\n",
       "ps        6384\n",
       "Name: channel, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('category')['channel'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49999, 4)\n",
      "(49281, 4)\n",
      "CPU times: user 4min 45s, sys: 7.59 s, total: 4min 52s\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def set_target(x):\n",
    "    if x == 'afs':\n",
    "        return 0\n",
    "\n",
    "    if x == 'other':\n",
    "        return 1\n",
    "\n",
    "    return 2\n",
    "\n",
    "options = (\n",
    "    'word_with_digits',\n",
    "    #'nltk_stopwords',\n",
    "    'manual_stopwords',\n",
    "    'lemmatization',\n",
    "    'punctuation'\n",
    ")\n",
    "\n",
    "df['cleaned_text'] = df['message'].apply(lambda x: preprocess(x, options))\n",
    "print(df.shape)\n",
    "df = df[df['cleaned_text'] != '']\n",
    "print(df.shape)\n",
    "\n",
    "y = df['category'].apply(set_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.92 s, sys: 333 ms, total: 8.25 s\n",
      "Wall time: 8.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    lowercase=False,\n",
    "    max_df=0.95,\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
       "          multi_class='ovr', penalty='l2', random_state=100, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(\n",
    "    C=0.01,\n",
    "    random_state=rs, \n",
    "    max_iter=10000,\n",
    "    class_weight='balanced',\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      7006\n",
      "           1       0.54      0.46      0.50      1630\n",
      "           2       0.64      0.78      0.70      1221\n",
      "\n",
      "    accuracy                           0.80      9857\n",
      "   macro avg       0.69      0.71      0.70      9857\n",
      "weighted avg       0.80      0.80      0.80      9857\n",
      "\n",
      "Train               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90     27972\n",
      "           1       0.56      0.47      0.52      6423\n",
      "           2       0.66      0.79      0.72      5029\n",
      "\n",
      "    accuracy                           0.81     39424\n",
      "   macro avg       0.71      0.72      0.71     39424\n",
      "weighted avg       0.81      0.81      0.81     39424\n",
      "\n",
      "CPU times: user 116 ms, sys: 7.66 ms, total: 123 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# calc statistic\n",
    "predicted_test = clf.predict(X_test)\n",
    "predicted_train = clf.predict(X_train)\n",
    "\n",
    "print('Test', metrics.classification_report(y_test, predicted_test))\n",
    "print('Train', metrics.classification_report(y_train, predicted_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open(\"models/multiclf_tfidf.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('models/multiclf_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_saved = pickle.load(open(\"./models/multiclf_tfidf.pickle\", \"rb\"))\n",
    "model_saved = pickle.load(open(\"./models/multiclf_model.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['hello i want to payment but it is blocked']\n",
    "\n",
    "sample_vec = vectorizer_saved.transform(test_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_saved.predict(sample_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
