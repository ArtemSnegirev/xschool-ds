{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import string\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "rs = 100\n",
    "\n",
    "nltk_sw = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "manual_sw = set([\n",
    "    'chat',\n",
    "    'transcript',\n",
    "    'alexandra',\n",
    "    'visitor',\n",
    "    'xsolla',\n",
    "    'please',\n",
    "    'thank',\n",
    "    'hello',\n",
    "    'ok',\n",
    "    'hi'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('datasets/data3.csv').drop(columns='Unnamed: 0')\n",
    "# data = data.sample(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 13.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def filter_text(x):\n",
    "    x = x[:1000]\n",
    "    \n",
    "    try:\n",
    "        res = detect(x) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return res\n",
    "\n",
    "# df = data[data['description'].apply(filter_text)]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_word_with_digits = re.compile('([A-Za-z]*[\\d]+[\\w]*|[\\d]+[A-Za-z]+[\\w]*)')\n",
    "\n",
    "def preprocess(text, options=()):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove chars has not 31-128 index in ascii table\n",
    "    text = ''.join([i if 31 < ord(i) < 128 else ' ' for i in text])\n",
    "    \n",
    "    if 'word_with_digits' in options:\n",
    "        text = match_word_with_digits.sub(r' ', text)\n",
    "    \n",
    "    # remove double spaces and apply lower transformation\n",
    "    tokens = word_tokenize(text.strip())\n",
    "    \n",
    "    sw = set()\n",
    "    \n",
    "    if 'nltk_stopwords' in options:\n",
    "        sw = sw.union(nltk_sw)\n",
    "    \n",
    "    if 'manual_stopwords' in options:\n",
    "        sw = sw.union(manual_sw)\n",
    "        \n",
    "    if len(sw) > 0:\n",
    "        tokens = [t for t in tokens if not t in sw]\n",
    "        \n",
    "    if 'lemmatization' in options:\n",
    "        # apply lemmatizer\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "        \n",
    "    if 'punctuation' in options:\n",
    "        # remove punctuation\n",
    "        tokens = [t for t in tokens if t not in string.punctuation]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == 'svm':\n",
    "        return LinearSVC(\n",
    "            C=0.5,\n",
    "            random_state=rs, \n",
    "            max_iter=10000,\n",
    "        )\n",
    "    \n",
    "    if model_name == 'gb':\n",
    "        return GradientBoostingClassifier(\n",
    "            random_state=rs\n",
    "        )\n",
    "    \n",
    "    if model_name == 'ann':\n",
    "        return MLPClassifier(\n",
    "            hidden_layer_sizes=(100),\n",
    "            validation_fraction=0.2,\n",
    "            learning_rate_init=0.0001,\n",
    "            early_stopping=True,\n",
    "            random_state=rs,\n",
    "            alpha=0.01\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "        \n",
    "    def __iter__(self):            \n",
    "        for sent in self.sentences:\n",
    "            yield sent.split()\n",
    "            \n",
    "def avg_pool(text, model):\n",
    "    \n",
    "    tokens = np.array(text.split())\n",
    "    tokens = [t for t in tokens if t in model]\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        # TODO remove\n",
    "        return np.zeros(model['paypal'].shape)\n",
    "        \n",
    "    return model[tokens].sum(axis=0) / len(tokens)\n",
    "\n",
    "def get_text_repr(text_repr_name, X):\n",
    "    \n",
    "    if text_repr_name in ['word2vec', 'fasttext']:\n",
    "        params = {\n",
    "            'size': 50,\n",
    "            'seed': rs,\n",
    "            'sentences': Corpus(X),\n",
    "            'min_count': 10,\n",
    "            'negative': 10,\n",
    "            'sg': 0\n",
    "        }\n",
    "        \n",
    "        model_class = Word2Vec if text_repr_name == 'word2vec' else FastText\n",
    "        model_obj = model_class(**params)    \n",
    "        \n",
    "        return np.array([avg_pool(text, model_obj) for text in X])\n",
    "    \n",
    "    if text_repr_name in ['tfidf', 'bow']:\n",
    "        params = {\n",
    "            'lowercase': False,\n",
    "            'max_df': 0.95\n",
    "        }\n",
    "        \n",
    "        model_class = CountVectorizer if text_repr_name == 'bow' else TfidfVectorizer\n",
    "        model_obj = model_class(**params)\n",
    "        \n",
    "        return model_obj.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preprocess_options = [\n",
    "    'nltk_stopwords',\n",
    "    'manual_stopwords',\n",
    "    'lemmatization',\n",
    "    'punctuation'\n",
    "]\n",
    "\n",
    "text_repr_options = [\n",
    "    'word2vec',\n",
    "    'fasttext',\n",
    "    'tfidf',\n",
    "    'bow'\n",
    "]\n",
    "\n",
    "model_options = [\n",
    "    'svm',\n",
    "    'gb',\n",
    "    'ann'\n",
    "]\n",
    "\n",
    "preprocess_options = []\n",
    "\n",
    "for i in range(len(all_preprocess_options)):\n",
    "    options = list(itertools.combinations(all_preprocess_options, i + 1))\n",
    "    preprocess_options = preprocess_options + options\n",
    "    \n",
    "training_options_list = list(itertools.product(\n",
    "    preprocess_options, \n",
    "    text_repr_options, \n",
    "    model_options\n",
    "))\n",
    "\n",
    "training_options_list = [op for op in training_options_list if not (op[1] in ['tfidf', 'bow'] and op[2] in ['ann', 'gb'])]\n",
    "len(training_options_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [3:17:43<00:00, 98.86s/it]  \n"
     ]
    }
   ],
   "source": [
    "# about 3 hours!\n",
    "\n",
    "def run_experiment():\n",
    "    last_preprocess = None\n",
    "    last_text_repr = None\n",
    "\n",
    "    scores = [\n",
    "        metrics.precision_score,\n",
    "        metrics.accuracy_score,\n",
    "        metrics.roc_auc_score,\n",
    "        metrics.recall_score,\n",
    "        metrics.f1_score\n",
    "    ]\n",
    "\n",
    "    df_experiment = pd.DataFrame()\n",
    "\n",
    "    for training_options in tqdm(training_options_list):\n",
    "        cur_preprocess = training_options[0]\n",
    "        cur_text_repr = training_options[1]\n",
    "        model_name = training_options[2]\n",
    "\n",
    "        if cur_preprocess != last_preprocess:\n",
    "            df['cleaned_text'] = df['description'].apply(lambda x: preprocess(x, cur_preprocess))\n",
    "            y = 1 - df['category_flag'].to_numpy()\n",
    "\n",
    "        if cur_text_repr != last_text_repr:\n",
    "            X_vector = get_text_repr(cur_text_repr, df['cleaned_text'])\n",
    "\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_vector, y, test_size=0.2, random_state=rs)\n",
    "\n",
    "        clf = get_model(model_name)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # calc statistic\n",
    "        acc_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "        acc_scores = np.mean(acc_scores)\n",
    "\n",
    "        predicted_test = clf.predict(X_test)\n",
    "        predicted_train = clf.predict(X_train)\n",
    "\n",
    "        calc_score = lambda score, true, predicted: score(true, predicted)\n",
    "\n",
    "        test_scores = {f'test_{s.__name__}': calc_score(s, y_test, predicted_test) for s in scores}\n",
    "        train_scores = {f'train_{s.__name__}': calc_score(s, y_train, predicted_train) for s in scores}\n",
    "\n",
    "        # add to dataframe\n",
    "        df_experiment = df_experiment.append({\n",
    "            'prepoccess': cur_preprocess,\n",
    "            'text_repr': cur_text_repr,\n",
    "            'model': model_name,\n",
    "            'cv_accuracy': acc_scores,\n",
    "            **test_scores,\n",
    "            **train_scores\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        last_preprocess = cur_preprocess\n",
    "        last_text_repr = cur_text_repr\n",
    "    \n",
    "    df_experiment.to_csv('datasets/experiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>model</th>\n",
       "      <th>prepoccess</th>\n",
       "      <th>test_accuracy_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "      <th>test_roc_auc_score</th>\n",
       "      <th>text_repr</th>\n",
       "      <th>train_accuracy_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>train_roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.921569</td>\n",
       "      <td>svm</td>\n",
       "      <td>(manual_stopwords,)</td>\n",
       "      <td>0.908031</td>\n",
       "      <td>0.760656</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.713846</td>\n",
       "      <td>0.835933</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966060</td>\n",
       "      <td>0.910674</td>\n",
       "      <td>0.946167</td>\n",
       "      <td>0.877747</td>\n",
       "      <td>0.932743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.921569</td>\n",
       "      <td>svm</td>\n",
       "      <td>(manual_stopwords, punctuation)</td>\n",
       "      <td>0.908031</td>\n",
       "      <td>0.760656</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.713846</td>\n",
       "      <td>0.835933</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966060</td>\n",
       "      <td>0.910674</td>\n",
       "      <td>0.946167</td>\n",
       "      <td>0.877747</td>\n",
       "      <td>0.932743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.921647</td>\n",
       "      <td>svm</td>\n",
       "      <td>(punctuation,)</td>\n",
       "      <td>0.907717</td>\n",
       "      <td>0.760033</td>\n",
       "      <td>0.812609</td>\n",
       "      <td>0.713846</td>\n",
       "      <td>0.835735</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966060</td>\n",
       "      <td>0.910674</td>\n",
       "      <td>0.946167</td>\n",
       "      <td>0.877747</td>\n",
       "      <td>0.932743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.921254</td>\n",
       "      <td>svm</td>\n",
       "      <td>(lemmatization,)</td>\n",
       "      <td>0.907402</td>\n",
       "      <td>0.759411</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.713846</td>\n",
       "      <td>0.835537</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.965667</td>\n",
       "      <td>0.909656</td>\n",
       "      <td>0.944899</td>\n",
       "      <td>0.876948</td>\n",
       "      <td>0.932197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.921254</td>\n",
       "      <td>svm</td>\n",
       "      <td>(lemmatization, punctuation)</td>\n",
       "      <td>0.907402</td>\n",
       "      <td>0.759411</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.713846</td>\n",
       "      <td>0.835537</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.965667</td>\n",
       "      <td>0.909656</td>\n",
       "      <td>0.944899</td>\n",
       "      <td>0.876948</td>\n",
       "      <td>0.932197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.921175</td>\n",
       "      <td>svm</td>\n",
       "      <td>(manual_stopwords, lemmatization)</td>\n",
       "      <td>0.907087</td>\n",
       "      <td>0.758395</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.712308</td>\n",
       "      <td>0.834768</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.965667</td>\n",
       "      <td>0.909619</td>\n",
       "      <td>0.945282</td>\n",
       "      <td>0.876548</td>\n",
       "      <td>0.932046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.921175</td>\n",
       "      <td>svm</td>\n",
       "      <td>(manual_stopwords, lemmatization, punctuation)</td>\n",
       "      <td>0.907087</td>\n",
       "      <td>0.758395</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.712308</td>\n",
       "      <td>0.834768</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.965667</td>\n",
       "      <td>0.909619</td>\n",
       "      <td>0.945282</td>\n",
       "      <td>0.876548</td>\n",
       "      <td>0.932046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.920624</td>\n",
       "      <td>svm</td>\n",
       "      <td>(nltk_stopwords, manual_stopwords, lemmatization)</td>\n",
       "      <td>0.906772</td>\n",
       "      <td>0.757774</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.712308</td>\n",
       "      <td>0.834570</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966690</td>\n",
       "      <td>0.912513</td>\n",
       "      <td>0.945969</td>\n",
       "      <td>0.881342</td>\n",
       "      <td>0.934492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.920624</td>\n",
       "      <td>svm</td>\n",
       "      <td>(nltk_stopwords, manual_stopwords, lemmatizati...</td>\n",
       "      <td>0.906772</td>\n",
       "      <td>0.757774</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.712308</td>\n",
       "      <td>0.834570</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966690</td>\n",
       "      <td>0.912513</td>\n",
       "      <td>0.945969</td>\n",
       "      <td>0.881342</td>\n",
       "      <td>0.934492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.921805</td>\n",
       "      <td>svm</td>\n",
       "      <td>(nltk_stopwords,)</td>\n",
       "      <td>0.906457</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.809107</td>\n",
       "      <td>0.710769</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966218</td>\n",
       "      <td>0.911309</td>\n",
       "      <td>0.944302</td>\n",
       "      <td>0.880543</td>\n",
       "      <td>0.933897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.920702</td>\n",
       "      <td>svm</td>\n",
       "      <td>(nltk_stopwords, lemmatization)</td>\n",
       "      <td>0.906457</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.809107</td>\n",
       "      <td>0.710769</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966612</td>\n",
       "      <td>0.912324</td>\n",
       "      <td>0.945564</td>\n",
       "      <td>0.881342</td>\n",
       "      <td>0.934443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.921805</td>\n",
       "      <td>svm</td>\n",
       "      <td>(nltk_stopwords, punctuation)</td>\n",
       "      <td>0.906457</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.809107</td>\n",
       "      <td>0.710769</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966218</td>\n",
       "      <td>0.911309</td>\n",
       "      <td>0.944302</td>\n",
       "      <td>0.880543</td>\n",
       "      <td>0.933897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.920702</td>\n",
       "      <td>svm</td>\n",
       "      <td>(nltk_stopwords, lemmatization, punctuation)</td>\n",
       "      <td>0.906457</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.809107</td>\n",
       "      <td>0.710769</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966612</td>\n",
       "      <td>0.912324</td>\n",
       "      <td>0.945564</td>\n",
       "      <td>0.881342</td>\n",
       "      <td>0.934443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.921884</td>\n",
       "      <td>svm</td>\n",
       "      <td>(nltk_stopwords, manual_stopwords)</td>\n",
       "      <td>0.905827</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>0.807356</td>\n",
       "      <td>0.709231</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966060</td>\n",
       "      <td>0.910858</td>\n",
       "      <td>0.944254</td>\n",
       "      <td>0.879744</td>\n",
       "      <td>0.933497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.921884</td>\n",
       "      <td>svm</td>\n",
       "      <td>(nltk_stopwords, manual_stopwords, punctuation)</td>\n",
       "      <td>0.905827</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>0.807356</td>\n",
       "      <td>0.709231</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.966060</td>\n",
       "      <td>0.910858</td>\n",
       "      <td>0.944254</td>\n",
       "      <td>0.879744</td>\n",
       "      <td>0.933497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cv_accuracy model                                         prepoccess  \\\n",
       "14      0.921569   svm                                (manual_stopwords,)   \n",
       "70      0.921569   svm                    (manual_stopwords, punctuation)   \n",
       "30      0.921647   svm                                     (punctuation,)   \n",
       "22      0.921254   svm                                   (lemmatization,)   \n",
       "78      0.921254   svm                       (lemmatization, punctuation)   \n",
       "62      0.921175   svm                  (manual_stopwords, lemmatization)   \n",
       "110     0.921175   svm     (manual_stopwords, lemmatization, punctuation)   \n",
       "86      0.920624   svm  (nltk_stopwords, manual_stopwords, lemmatization)   \n",
       "118     0.920624   svm  (nltk_stopwords, manual_stopwords, lemmatizati...   \n",
       "6       0.921805   svm                                  (nltk_stopwords,)   \n",
       "46      0.920702   svm                    (nltk_stopwords, lemmatization)   \n",
       "54      0.921805   svm                      (nltk_stopwords, punctuation)   \n",
       "102     0.920702   svm       (nltk_stopwords, lemmatization, punctuation)   \n",
       "38      0.921884   svm                 (nltk_stopwords, manual_stopwords)   \n",
       "94      0.921884   svm    (nltk_stopwords, manual_stopwords, punctuation)   \n",
       "\n",
       "     test_accuracy_score  test_f1_score  test_precision_score  \\\n",
       "14              0.908031       0.760656              0.814035   \n",
       "70              0.908031       0.760656              0.814035   \n",
       "30              0.907717       0.760033              0.812609   \n",
       "22              0.907402       0.759411              0.811189   \n",
       "78              0.907402       0.759411              0.811189   \n",
       "62              0.907087       0.758395              0.810858   \n",
       "110             0.907087       0.758395              0.810858   \n",
       "86              0.906772       0.757774              0.809441   \n",
       "118             0.906772       0.757774              0.809441   \n",
       "6               0.906457       0.756757              0.809107   \n",
       "46              0.906457       0.756757              0.809107   \n",
       "54              0.906457       0.756757              0.809107   \n",
       "102             0.906457       0.756757              0.809107   \n",
       "38              0.905827       0.755119              0.807356   \n",
       "94              0.905827       0.755119              0.807356   \n",
       "\n",
       "     test_recall_score  test_roc_auc_score text_repr  train_accuracy_score  \\\n",
       "14            0.713846            0.835933     tfidf              0.966060   \n",
       "70            0.713846            0.835933     tfidf              0.966060   \n",
       "30            0.713846            0.835735     tfidf              0.966060   \n",
       "22            0.713846            0.835537     tfidf              0.965667   \n",
       "78            0.713846            0.835537     tfidf              0.965667   \n",
       "62            0.712308            0.834768     tfidf              0.965667   \n",
       "110           0.712308            0.834768     tfidf              0.965667   \n",
       "86            0.712308            0.834570     tfidf              0.966690   \n",
       "118           0.712308            0.834570     tfidf              0.966690   \n",
       "6             0.710769            0.833800     tfidf              0.966218   \n",
       "46            0.710769            0.833800     tfidf              0.966612   \n",
       "54            0.710769            0.833800     tfidf              0.966218   \n",
       "102           0.710769            0.833800     tfidf              0.966612   \n",
       "38            0.709231            0.832833     tfidf              0.966060   \n",
       "94            0.709231            0.832833     tfidf              0.966060   \n",
       "\n",
       "     train_f1_score  train_precision_score  train_recall_score  \\\n",
       "14         0.910674               0.946167            0.877747   \n",
       "70         0.910674               0.946167            0.877747   \n",
       "30         0.910674               0.946167            0.877747   \n",
       "22         0.909656               0.944899            0.876948   \n",
       "78         0.909656               0.944899            0.876948   \n",
       "62         0.909619               0.945282            0.876548   \n",
       "110        0.909619               0.945282            0.876548   \n",
       "86         0.912513               0.945969            0.881342   \n",
       "118        0.912513               0.945969            0.881342   \n",
       "6          0.911309               0.944302            0.880543   \n",
       "46         0.912324               0.945564            0.881342   \n",
       "54         0.911309               0.944302            0.880543   \n",
       "102        0.912324               0.945564            0.881342   \n",
       "38         0.910858               0.944254            0.879744   \n",
       "94         0.910858               0.944254            0.879744   \n",
       "\n",
       "     train_roc_auc_score  \n",
       "14              0.932743  \n",
       "70              0.932743  \n",
       "30              0.932743  \n",
       "22              0.932197  \n",
       "78              0.932197  \n",
       "62              0.932046  \n",
       "110             0.932046  \n",
       "86              0.934492  \n",
       "118             0.934492  \n",
       "6               0.933897  \n",
       "46              0.934443  \n",
       "54              0.933897  \n",
       "102             0.934443  \n",
       "38              0.933497  \n",
       "94              0.933497  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_ = (df_experiment['model'] == 'svm') & (df_experiment['text_repr'] == 'tfidf')\n",
    "\n",
    "# df_experiment.sort_values(by='cv_accuracy', ascending=False).head(50)\n",
    "\n",
    "df_experiment[filter_].sort_values(by='test_accuracy_score', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_roc_auc_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>train_roc_auc_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>text_repr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ann</th>\n",
       "      <th>fasttext</th>\n",
       "      <td>0.889467</td>\n",
       "      <td>0.669805</td>\n",
       "      <td>0.781514</td>\n",
       "      <td>0.717429</td>\n",
       "      <td>0.807849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.896443</td>\n",
       "      <td>0.689150</td>\n",
       "      <td>0.792081</td>\n",
       "      <td>0.723498</td>\n",
       "      <td>0.811164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gb</th>\n",
       "      <th>fasttext</th>\n",
       "      <td>0.886154</td>\n",
       "      <td>0.645138</td>\n",
       "      <td>0.760428</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.815228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.890606</td>\n",
       "      <td>0.669958</td>\n",
       "      <td>0.774481</td>\n",
       "      <td>0.755918</td>\n",
       "      <td>0.824406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">svm</th>\n",
       "      <th>bow</th>\n",
       "      <td>0.898963</td>\n",
       "      <td>0.720603</td>\n",
       "      <td>0.821418</td>\n",
       "      <td>0.989191</td>\n",
       "      <td>0.990254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fasttext</th>\n",
       "      <td>0.886301</td>\n",
       "      <td>0.652032</td>\n",
       "      <td>0.768731</td>\n",
       "      <td>0.685414</td>\n",
       "      <td>0.786992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>0.921311</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.834548</td>\n",
       "      <td>0.910972</td>\n",
       "      <td>0.933292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.892049</td>\n",
       "      <td>0.673883</td>\n",
       "      <td>0.780783</td>\n",
       "      <td>0.703768</td>\n",
       "      <td>0.798527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cv_accuracy  test_f1_score  test_roc_auc_score  \\\n",
       "model text_repr                                                   \n",
       "ann   fasttext      0.889467       0.669805            0.781514   \n",
       "      word2vec      0.896443       0.689150            0.792081   \n",
       "gb    fasttext      0.886154       0.645138            0.760428   \n",
       "      word2vec      0.890606       0.669958            0.774481   \n",
       "svm   bow           0.898963       0.720603            0.821418   \n",
       "      fasttext      0.886301       0.652032            0.768731   \n",
       "      tfidf         0.921311       0.757985            0.834548   \n",
       "      word2vec      0.892049       0.673883            0.780783   \n",
       "\n",
       "                 train_f1_score  train_roc_auc_score  \n",
       "model text_repr                                       \n",
       "ann   fasttext         0.717429             0.807849  \n",
       "      word2vec         0.723498             0.811164  \n",
       "gb    fasttext         0.741667             0.815228  \n",
       "      word2vec         0.755918             0.824406  \n",
       "svm   bow              0.989191             0.990254  \n",
       "      fasttext         0.685414             0.786992  \n",
       "      tfidf            0.910972             0.933292  \n",
       "      word2vec         0.703768             0.798527  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_experiment.groupby(['model', 'text_repr'])[[\n",
    "    'cv_accuracy', \n",
    "    'test_f1_score', \n",
    "    'test_roc_auc_score', \n",
    "    'train_f1_score',\n",
    "    'train_roc_auc_score'\n",
    "]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/data3_english.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15874, 5)\n",
      "(15798, 5)\n",
      "CPU times: user 1min 46s, sys: 1.36 s, total: 1min 47s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "options = (\n",
    "    'word_with_digits',\n",
    "#     'nltk_stopwords',\n",
    "    'manual_stopwords',\n",
    "    'lemmatization',\n",
    "    'punctuation'\n",
    ")\n",
    "\n",
    "df['cleaned_text'] = df['description'].apply(lambda x: preprocess(x, options))\n",
    "print(df.shape)\n",
    "df = df[df['cleaned_text'] != '']\n",
    "print(df.shape)\n",
    "\n",
    "y = 1 - df['category_flag'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.78 s, sys: 165 ms, total: 3.94 s\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=False,\n",
    "    max_df=0.95,\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# svd = TruncatedSVD(n_components=100, random_state=rs)\n",
    "# X = svd.fit_transform(X)\n",
    "\n",
    "# X_w2v = get_text_repr('word2vec', df['cleaned_text'])\n",
    "\n",
    "# X = np.concatenate([X, X_w2v], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
       "          multi_class='ovr', penalty='l2', random_state=100, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(\n",
    "    C=0.01,\n",
    "    random_state=rs, \n",
    "    max_iter=10000,\n",
    "    class_weight='balanced',\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      2514\n",
      "           1       0.64      0.89      0.74       646\n",
      "\n",
      "    accuracy                           0.88      3160\n",
      "   macro avg       0.80      0.88      0.83      3160\n",
      "weighted avg       0.90      0.88      0.88      3160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92     10161\n",
      "           1       0.64      0.90      0.75      2477\n",
      "\n",
      "    accuracy                           0.88     12638\n",
      "   macro avg       0.81      0.89      0.84     12638\n",
      "weighted avg       0.91      0.88      0.89     12638\n",
      "\n",
      "CPU times: user 60.3 ms, sys: 3.61 ms, total: 63.9 ms\n",
      "Wall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# calc statistic\n",
    "predicted_test = clf.predict(X_test)\n",
    "predicted_train = clf.predict(X_train)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted_test))\n",
    "print(metrics.classification_report(y_train, predicted_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.73      0.59      3112\n",
      "         1.0       0.51      0.28      0.36      3160\n",
      "\n",
      "    accuracy                           0.50      6272\n",
      "   macro avg       0.51      0.51      0.48      6272\n",
      "weighted avg       0.51      0.50      0.48      6272\n",
      "\n",
      "[[2267  845]\n",
      " [2267  893]]\n"
     ]
    }
   ],
   "source": [
    "overfit_size_test = X_test.shape[0]\n",
    "overfit_size_train = X_train.shape[0]\n",
    "\n",
    "prob = overfit_size_test / overfit_size_train\n",
    "\n",
    "random_sample = np.random.choice(\n",
    "    [True, False], \n",
    "    size=overfit_size_train, \n",
    "    p=[prob, 1 - prob]\n",
    ")\n",
    "\n",
    "X_overfit = X_train[random_sample]\n",
    "\n",
    "overfit_size_train = X_overfit.shape[0]\n",
    "\n",
    "X_overfit = vstack((X_overfit, X_test), format='csr')\n",
    "y_overfit = np.concatenate([np.zeros(overfit_size_train), np.ones(overfit_size_test)])\n",
    "\n",
    "predicted_overfit = clf.predict(X_overfit)\n",
    "print(metrics.classification_report(y_overfit, predicted_overfit))\n",
    "print(metrics.confusion_matrix(y_overfit, predicted_overfit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_by_value(d, v):\n",
    "    return list(d.keys())[list(d.values()).index(v)]\n",
    "\n",
    "def print_n_top(vocab, values, n=10, ascending=False):\n",
    "    indexes = values.argsort()\n",
    "    \n",
    "    if ascending:\n",
    "        indexes = indexes[::-1]\n",
    "    \n",
    "    for i in range(n):\n",
    "        idx = indexes[i]\n",
    "        print(get_key_by_value(vocab, idx), round(values[idx], 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payment 1.26\n",
      "day 1.54\n",
      "help 1.63\n",
      "contact 1.65\n",
      "issue 1.68\n",
      "account 1.74\n",
      "transaction 1.75\n",
      "email 1.77\n",
      "wait 1.83\n",
      "provide 1.83\n",
      "refund 1.83\n",
      "take 1.84\n",
      "number 1.88\n",
      "game 1.93\n",
      "check 1.95\n",
      "may 1.96\n",
      "information 1.98\n",
      "patience 1.99\n",
      "purchase 2.0\n",
      "happy 2.0\n"
     ]
    }
   ],
   "source": [
    "print_n_top(vectorizer.vocabulary_, vectorizer.idf_, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card 1.02\n",
      "error 0.84\n",
      "try 0.77\n",
      "bank 0.64\n",
      "paypal 0.61\n",
      "page 0.6\n",
      "code 0.57\n",
      "method 0.53\n",
      "pay 0.52\n",
      "browser 0.51\n",
      "option 0.49\n",
      "unfortunately 0.46\n",
      "amazon 0.45\n",
      "clear 0.45\n",
      "retry 0.44\n",
      "trying 0.42\n",
      "another 0.42\n",
      "buy 0.4\n",
      "pop 0.39\n",
      "choose 0.39\n"
     ]
    }
   ],
   "source": [
    "print_n_top(vectorizer.vocabulary_, clf.coef_[0], n=20, ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
